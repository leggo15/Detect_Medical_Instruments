{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T07:54:35.339883Z",
     "iopub.status.busy": "2024-11-19T07:54:35.339883Z",
     "iopub.status.idle": "2024-11-19T07:54:40.771084Z",
     "shell.execute_reply": "2024-11-19T07:54:40.771084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import tarfile\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm  # For progress bar\n",
    "import wandb\n",
    "from PIL import ImageOps\n",
    "\n",
    "# PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# PyTorch-related Libraries\n",
    "from torchvision.transforms import Resize, Pad\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torchvision.transforms import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T07:54:40.773592Z",
     "iopub.status.busy": "2024-11-19T07:54:40.772089Z",
     "iopub.status.idle": "2024-11-19T07:54:43.893119Z",
     "shell.execute_reply": "2024-11-19T07:54:43.893119Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"Deep-Learning-Exam\",\n",
    "    name=\"base-model\",\n",
    "    dir=\"./wandb_logs\",\n",
    "    config={\n",
    "        \"version\": \"v1.0.0\",\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"architecture\": \"UNet\",\n",
    "        \"encoder\": \"resnet34\",\n",
    "        \"dataset\": \"Kvasir-Instrument\",\n",
    "    },\n",
    "    settings=wandb.Settings(init_timeout=900)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T07:54:43.894123Z",
     "iopub.status.busy": "2024-11-19T07:54:43.894123Z",
     "iopub.status.idle": "2024-11-19T07:54:43.921831Z",
     "shell.execute_reply": "2024-11-19T07:54:43.921831Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T07:54:43.923396Z",
     "iopub.status.busy": "2024-11-19T07:54:43.923396Z",
     "iopub.status.idle": "2024-11-19T07:54:43.940981Z",
     "shell.execute_reply": "2024-11-19T07:54:43.940981Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "dataset_dir = '../data/kvasir-instrument'\n",
    "images_tar = os.path.join(dataset_dir, 'images.tar.gz')\n",
    "masks_tar = os.path.join(dataset_dir, 'masks.tar.gz')\n",
    "train_txt = os.path.join(dataset_dir, 'train.txt')\n",
    "test_txt = os.path.join(dataset_dir, 'test.txt')\n",
    "images_dir = os.path.join(dataset_dir, 'images')\n",
    "masks_dir = os.path.join(dataset_dir, 'masks')\n",
    "bbox_json = os.path.join(dataset_dir, 'bboxes.json')\n",
    "\n",
    "# Function to extract tar.gz files\n",
    "def extract_tar(tar_path, extract_path):\n",
    "    if not os.path.exists(extract_path):\n",
    "        with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "            tar.extractall(path=extract_path)\n",
    "            print(f\"Extracted {tar_path} to {extract_path}.\")\n",
    "    else:\n",
    "        print(f\"Directory {extract_path} already exists. Skipping extraction.\")\n",
    "\n",
    "# Function to load file splits\n",
    "def load_split(file_path):\n",
    "    return [line.strip() for line in open(file_path, 'r')] if os.path.exists(file_path) else []\n",
    "\n",
    "# Verify files based on splits\n",
    "def verify_files(filenames, directory, extensions=('.jpg', '.jpeg', '.png')):\n",
    "    return [os.path.join(directory, f + ext) for f in filenames for ext in extensions if os.path.exists(os.path.join(directory, f + ext))]\n",
    "\n",
    "# Extract dataset\n",
    "extract_tar(images_tar, images_dir)\n",
    "extract_tar(masks_tar, masks_dir)\n",
    "\n",
    "# Load train and test splits\n",
    "train_filenames = load_split(train_txt)\n",
    "test_filenames = load_split(test_txt)\n",
    "\n",
    "# Load bboxes.json\n",
    "with open(bbox_json, 'r') as f:\n",
    "    bboxes = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T07:54:43.942549Z",
     "iopub.status.busy": "2024-11-19T07:54:43.942549Z",
     "iopub.status.idle": "2024-11-19T07:54:43.946998Z",
     "shell.execute_reply": "2024-11-19T07:54:43.946998Z"
    }
   },
   "outputs": [],
   "source": [
    "class KvasirInstrumentDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, image_ids, target_size=(576, 576)):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.image_ids = image_ids\n",
    "        self.target_size = target_size\n",
    "        self.resize_to_target = Resize(self.target_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image_path = os.path.join(self.images_dir, f\"{image_id}.jpg\")\n",
    "        mask_path = os.path.join(self.masks_dir, f\"{image_id}.png\")\n",
    "\n",
    "        # Load and process the image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        # Pad to square to prevent stretching of the images.\n",
    "        image, mask = self.pad_to_square(image, mask)\n",
    "        \n",
    "        # Initialize separate resize transforms for images and masks\n",
    "        self.resize_to_target_image = Resize(self.target_size, interpolation=InterpolationMode.BILINEAR)\n",
    "        self.resize_to_target_mask = Resize(self.target_size, interpolation=InterpolationMode.NEAREST)\n",
    "\n",
    "        # Resize to target size\n",
    "        image = self.resize_to_target_image(image)\n",
    "        mask = self.resize_to_target_mask(mask)\n",
    "\n",
    "\n",
    "        # Convert to tensors\n",
    "        image = torch.tensor(np.array(image, dtype=np.float32) / 255.0).permute(2, 0, 1)  # [C, H, W]\n",
    "        mask = torch.tensor(np.array(mask, dtype=np.float32) / 255.0).unsqueeze(0)  # [1, H, W]\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def pad_to_square(self, image, mask):\n",
    "        w, h = image.size\n",
    "        max_side = max(w, h)\n",
    "        left = (max_side - w) // 2\n",
    "        top = (max_side - h) // 2\n",
    "        right = max_side - w - left\n",
    "        bottom = max_side - h - top\n",
    "        padding = (left, top, right, bottom)\n",
    "\n",
    "        image = ImageOps.expand(image, border=padding, fill=0)\n",
    "        mask = ImageOps.expand(mask, border=padding, fill=0)\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T07:54:43.948002Z",
     "iopub.status.busy": "2024-11-19T07:54:43.948002Z",
     "iopub.status.idle": "2024-11-19T07:54:43.984933Z",
     "shell.execute_reply": "2024-11-19T07:54:43.984933Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "train_size = int(0.8 * len(train_filenames))\n",
    "val_size = len(train_filenames) - train_size\n",
    "train_ids, val_ids = random_split(train_filenames, [train_size, val_size])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = KvasirInstrumentDataset(images_dir, masks_dir, train_ids)\n",
    "val_dataset = KvasirInstrumentDataset(images_dir, masks_dir, val_ids)\n",
    "test_dataset = KvasirInstrumentDataset(images_dir, masks_dir, test_filenames)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T07:54:43.986937Z",
     "iopub.status.busy": "2024-11-19T07:54:43.985937Z",
     "iopub.status.idle": "2024-11-19T07:54:43.991255Z",
     "shell.execute_reply": "2024-11-19T07:54:43.991255Z"
    }
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.conv_block(512, 1024, dropout=0.1)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512, dropout=0.2)\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256, dropout=0.1)\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        \n",
    "        # Final Output\n",
    "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "    def conv_block(self, in_channels, out_channels, dropout=None):\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if dropout is not None:\n",
    "            layers.append(nn.Dropout2d(p=dropout))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(self.pool(enc1))\n",
    "        enc3 = self.enc3(self.pool(enc2))\n",
    "        enc4 = self.enc4(self.pool(enc3))\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(self.pool(enc4))\n",
    "        \n",
    "        # Decoder\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.dec4(dec4)\n",
    "        \n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.dec3(dec3)\n",
    "        \n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.dec2(dec2)\n",
    "        \n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.dec1(dec1)\n",
    "        \n",
    "        return self.final(dec1)\n",
    "\n",
    "    def pool(self, x):\n",
    "        return nn.MaxPool2d(kernel_size=2, stride=2)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T07:54:43.992259Z",
     "iopub.status.busy": "2024-11-19T07:54:43.992259Z",
     "iopub.status.idle": "2024-11-19T07:54:44.370828Z",
     "shell.execute_reply": "2024-11-19T07:54:44.370828Z"
    }
   },
   "outputs": [],
   "source": [
    "model = UNet(in_channels=3, out_channels=1).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # For binary segmentation tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T07:54:44.372832Z",
     "iopub.status.busy": "2024-11-19T07:54:44.372832Z",
     "iopub.status.idle": "2024-11-19T07:54:44.376694Z",
     "shell.execute_reply": "2024-11-19T07:54:44.376398Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "def iou_score(preds, masks):  # Intersection Over Union\n",
    "    intersection = (preds * masks).sum((1, 2, 3))\n",
    "    union = ((preds + masks) > 0).sum((1, 2, 3))\n",
    "    return (intersection / union).mean().item()\n",
    "\n",
    "def dice_coefficient(preds, masks):\n",
    "    intersection = (preds * masks).sum((1, 2, 3))\n",
    "    dice = (2 * intersection) / (preds.sum((1, 2, 3)) + masks.sum((1, 2, 3)))\n",
    "    return dice.mean().item()\n",
    "\n",
    "def precision(preds, masks):\n",
    "    tp = (preds * masks).sum((1, 2, 3))  # True Positives\n",
    "    fp = ((preds * (1 - masks))).sum((1, 2, 3))  # False Positives\n",
    "    return (tp / (tp + fp + 1e-7)).mean().item()\n",
    "\n",
    "def recall(preds, masks):\n",
    "    tp = (preds * masks).sum((1, 2, 3))  # True Positives\n",
    "    fn = ((1 - preds) * masks).sum((1, 2, 3))  # False Negatives\n",
    "    return (tp / (tp + fn + 1e-7)).mean().item()\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    return 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "\n",
    "def pixel_accuracy(preds, masks):\n",
    "    correct = (preds == masks).sum((1, 2, 3))\n",
    "    total = torch.numel(preds[0])  # Total pixels per image\n",
    "    return (correct / total).mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T07:54:44.378757Z",
     "iopub.status.busy": "2024-11-19T07:54:44.378244Z",
     "iopub.status.idle": "2024-11-19T07:54:44.385067Z",
     "shell.execute_reply": "2024-11-19T07:54:44.385067Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "\n",
    "# Define the training loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, patience=3):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    model.to(device)\n",
    "\n",
    "    total_training_start = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        epoch_loss = 0\n",
    "        epoch_iou = 0\n",
    "        epoch_dice = 0\n",
    "        epoch_precision = 0\n",
    "        epoch_recall = 0\n",
    "        epoch_pixel_acc = 0\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        \n",
    "        for images, masks in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "            images, masks = images.to(device, non_blocking=True), masks.to(device, non_blocking=True)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Threshold predictions at 0.5\n",
    "            binary_preds = (preds > 0.5).float()\n",
    "\n",
    "            # Calculate metrics\n",
    "            epoch_iou += iou_score(binary_preds, masks)\n",
    "            epoch_dice += dice_coefficient(binary_preds, masks)\n",
    "            epoch_precision += precision(binary_preds, masks)\n",
    "            epoch_recall += recall(binary_preds, masks)\n",
    "            epoch_pixel_acc += pixel_accuracy(binary_preds, masks)\n",
    "        \n",
    "        # Average metrics over the epoch\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        avg_iou = epoch_iou / len(train_loader)\n",
    "        avg_dice = epoch_dice / len(train_loader)\n",
    "        avg_precision = epoch_precision / len(train_loader)\n",
    "        avg_recall = epoch_recall / len(train_loader)\n",
    "        avg_pixel_acc = epoch_pixel_acc / len(train_loader)\n",
    "        avg_f1 = f1_score(avg_precision, avg_recall)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}, IoU: {avg_iou:.4f}, Dice: {avg_dice:.4f}, Precision: {avg_precision:.4f}, Recall: {avg_recall:.4f}, F1: {avg_f1:.4f}, Pixel Acc: {avg_pixel_acc:.4f}\")\n",
    "        \n",
    "        # Log to wandb\n",
    "        wandb.log({\n",
    "            \"train_loss\": avg_loss,\n",
    "            \"train_iou\": avg_iou,\n",
    "            \"train_dice\": avg_dice,\n",
    "            \"train_precision\": avg_precision,\n",
    "            \"train_recall\": avg_recall,\n",
    "            \"train_f1\": avg_f1,\n",
    "            \"train_pixel_acc\": avg_pixel_acc,\n",
    "        })\n",
    "\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0\n",
    "        val_iou = 0\n",
    "        val_dice = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images, masks = images.to(device, non_blocking=True), masks.to(device, non_blocking=True)\n",
    "                outputs = model(images)\n",
    "                preds = torch.sigmoid(outputs)\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Threshold predictions\n",
    "                binary_preds = (preds > 0.8).float()\n",
    "                \n",
    "                # Calculate metrics\n",
    "                val_iou += iou_score(binary_preds, masks)\n",
    "                val_dice += dice_coefficient(binary_preds, masks)\n",
    "        \n",
    "        # Average validation metrics\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_iou = val_iou / len(val_loader)\n",
    "        avg_val_dice = val_dice / len(val_loader)\n",
    "\n",
    "        \n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, IoU: {avg_val_iou:.4f}, Dice: {avg_val_dice:.4f},\")\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print('Early stopping triggered')\n",
    "                break\n",
    "            \n",
    "        model.train()  # Set model back to training mode for next epoch\n",
    "\n",
    "    total_training_time = time.time() - total_training_start\n",
    "    \n",
    "    print(\"Training complete\")\n",
    "\n",
    "    wandb.log({\"total_training_time\": total_training_time})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T07:54:44.387663Z",
     "iopub.status.busy": "2024-11-19T07:54:44.387146Z",
     "iopub.status.idle": "2024-11-19T08:03:32.471715Z",
     "shell.execute_reply": "2024-11-19T08:03:32.471715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T08:03:32.473719Z",
     "iopub.status.busy": "2024-11-19T08:03:32.473719Z",
     "iopub.status.idle": "2024-11-19T08:03:32.479782Z",
     "shell.execute_reply": "2024-11-19T08:03:32.479279Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_iou = 0\n",
    "    total_dice = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_pixel_acc = 0\n",
    "    results = []  # Store images, masks, and predictions for visualization\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for images, masks in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            images, masks = images.to(device, non_blocking=True), masks.to(device, non_blocking=True)\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
    "\n",
    "            # Threshold predictions at 0.5\n",
    "            binary_preds = (preds > 0.5).float()\n",
    "\n",
    "            # Store the results for visualization\n",
    "            results.append((images.cpu(), masks.cpu(), binary_preds.cpu()))\n",
    "\n",
    "            # Calculate metrics\n",
    "            total_iou += iou_score(binary_preds, masks)\n",
    "            total_dice += dice_coefficient(binary_preds, masks)\n",
    "            total_precision += precision(binary_preds, masks)\n",
    "            total_recall += recall(binary_preds, masks)\n",
    "            total_pixel_acc += pixel_accuracy(binary_preds, masks)\n",
    "\n",
    "    # Average metrics\n",
    "    avg_iou = total_iou / len(dataloader)\n",
    "    avg_dice = total_dice / len(dataloader)\n",
    "    avg_precision = total_precision / len(dataloader)\n",
    "    avg_recall = total_recall / len(dataloader)\n",
    "    avg_pixel_acc = total_pixel_acc / len(dataloader)\n",
    "    avg_f1 = f1_score(avg_precision, avg_recall)\n",
    "\n",
    "    print(f\"Final Model Accuracy - IoU: {avg_iou:.4f}, Dice: {avg_dice:.4f}, \"\n",
    "          f\"Precision: {avg_precision:.4f}, Recall: {avg_recall:.4f}, \"\n",
    "          f\"F1: {avg_f1:.4f}, Pixel Acc: {avg_pixel_acc:.4f}\")\n",
    "\n",
    "    # Log the evaluation metrics as scalars\n",
    "    wandb.log({\n",
    "        \"eval_iou\": avg_iou,\n",
    "        \"eval_dice\": avg_dice,\n",
    "        \"eval_precision\": avg_precision,\n",
    "        \"eval_recall\": avg_recall,\n",
    "        \"eval_f1\": avg_f1,\n",
    "        \"eval_pixel_acc\": avg_pixel_acc,\n",
    "    })\n",
    "\n",
    "    return results  # Return the results for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T08:03:32.481839Z",
     "iopub.status.busy": "2024-11-19T08:03:32.481325Z",
     "iopub.status.idle": "2024-11-19T08:03:32.485959Z",
     "shell.execute_reply": "2024-11-19T08:03:32.485442Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_results(results, num_samples=3):\n",
    "    for i in range(num_samples):\n",
    "        images, masks, preds = results[i]\n",
    "        for j in range(images.shape[0]):  # Iterate over batch size\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            \n",
    "            # Calculate metrics\n",
    "            iou = iou_score(preds[j].unsqueeze(0), masks[j].unsqueeze(0))\n",
    "            dice = dice_coefficient(preds[j].unsqueeze(0), masks[j].unsqueeze(0))\n",
    "            \n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(images[j].permute(1, 2, 0))  # Convert [C, H, W] to [H, W, C]\n",
    "            plt.title(\"Original Image\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(masks[j][0], cmap='gray')\n",
    "            plt.title(\"Ground Truth Mask\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(preds[j][0], cmap='gray')\n",
    "            plt.title(f\"Predicted Mask\\nIoU: {iou:.4f}, Dice: {dice:.4f}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.show()\n",
    "            if i >= num_samples - 1:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T08:03:32.487498Z",
     "iopub.status.busy": "2024-11-19T08:03:32.487498Z",
     "iopub.status.idle": "2024-11-19T08:03:42.463566Z",
     "shell.execute_reply": "2024-11-19T08:03:42.463566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "#model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate the model\n",
    "results = eval_model(model, test_loader, device)\n",
    "\n",
    "# Visualize results\n",
    "visualize_results(results, num_samples=3)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T08:03:42.465570Z",
     "iopub.status.busy": "2024-11-19T08:03:42.464569Z",
     "iopub.status.idle": "2024-11-19T08:03:42.643792Z",
     "shell.execute_reply": "2024-11-19T08:03:42.643792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleanup Section to Clear Memory with Memory Tracking\n",
    "\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "# Function to get current memory usage in GB\n",
    "def get_memory_usage_gb():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / (1024 ** 3)  # Convert bytes to GB\n",
    "\n",
    "# Memory usage before cleanup\n",
    "memory_before = get_memory_usage_gb()\n",
    "\n",
    "# List of variables to delete\n",
    "vars_to_delete = [\n",
    "    'model',\n",
    "    'train_dataset',\n",
    "    'val_dataset',\n",
    "    'test_dataset',\n",
    "    'train_loader',\n",
    "    'val_loader',\n",
    "    'test_loader',\n",
    "    'optimizer',\n",
    "    'scheduler',\n",
    "    'criterion',\n",
    "    'results',\n",
    "    'preds',\n",
    "    'binary_preds',\n",
    "    'outputs',\n",
    "    'images',\n",
    "    'masks',\n",
    "]\n",
    "\n",
    "for var in vars_to_delete:\n",
    "    if var in globals():\n",
    "        del globals()[var]\n",
    "\n",
    "# Clear CUDA cache if using GPU\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Collect garbage\n",
    "gc.collect()\n",
    "\n",
    "# Memory usage after cleanup\n",
    "memory_after = get_memory_usage_gb()\n",
    "\n",
    "# Display how much memory was cleared\n",
    "memory_cleared = memory_before - memory_after\n",
    "print(f\"Memory before cleanup: {memory_before:.2f} GB\")\n",
    "print(f\"Memory after cleanup: {memory_after:.2f} GB\")\n",
    "print(f\"Memory cleared: {memory_cleared:.2f} GB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
